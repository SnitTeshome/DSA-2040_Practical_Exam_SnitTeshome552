{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12dbdbc",
   "metadata": {},
   "source": [
    "# Task 1: *Section 2 - Data Mining*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e3474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris Data Preprocessing and Exploration\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a685cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Load the Iris dataset\n",
    "# ----------------------------\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target  # Add species as numeric label initially\n",
    "\n",
    "# Map numeric labels to actual species names for clarity\n",
    "iris_df['species'] = iris_df['species'].map({0:'setosa', 1:'versicolor', 2:'virginica'})\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Step 2: Preprocessing\n",
    "# ---------------------------------\n",
    "\n",
    "# 2a: Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(iris_df.isnull().sum())\n",
    "\n",
    "# 2b: Normalize features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "feature_cols = iris.feature_names\n",
    "iris_df[feature_cols] = scaler.fit_transform(iris_df[feature_cols])\n",
    "\n",
    "# 2c: Encode class labels if needed (label encoding shown here)\n",
    "label_encoder = LabelEncoder()\n",
    "iris_df['species_encoded'] = label_encoder.fit_transform(iris_df['species'])\n",
    "\n",
    "print(\"\\nDataset after preprocessing (first 5 rows):\")\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Step 3: Data Exploration\n",
    "# ---------------------------------\n",
    "\n",
    "# 3a: Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(iris_df.describe())\n",
    "\n",
    "# 3b: Visualizations\n",
    "# Pairplot\n",
    "sns.pairplot(iris_df, hue='species')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(iris_df[feature_cols].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# 3c: Identify potential outliers using boxplots\n",
    "plt.figure(figsize=(10,6))\n",
    "iris_df.boxplot(column=feature_cols)\n",
    "plt.title('Boxplot of Iris Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# Step 4: Train/Test Split Function\n",
    "# ---------------------------------\n",
    "\n",
    "def split_train_test(dataframe, test_size=0.2, random_state=42):\n",
    "    \"\"\"Splits the dataset into train and test sets.\"\"\"\n",
    "    X = dataframe[feature_cols]  # Features\n",
    "    y = dataframe['species_encoded']  # Target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state,\n",
    "                                                        stratify=y)  # Stratify to preserve class balance\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage\n",
    "X_train, X_test, y_train, y_test = split_train_test(iris_df)\n",
    "print(\"\\nTrain features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29403320",
   "metadata": {},
   "source": [
    "# *Task 2: Clustering with K-Means*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f574bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a: K-Means with k=3\n",
    "kmeans3 = KMeans(n_clusters=3, random_state=42)\n",
    "iris_df['cluster_k3'] = kmeans3.fit_predict(iris_df[feature_cols])\n",
    "\n",
    "# Compare with actual classes using ARI\n",
    "ari_k3 = adjusted_rand_score(iris_df['species_encoded'], iris_df['cluster_k3'])\n",
    "print(f\"Adjusted Rand Index for k=3: {ari_k3:.4f}\")\n",
    "# ----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de834aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b: Experiment with k=2 and k=4; Elbow curve\n",
    "inertia = []\n",
    "k_values = range(1, 6)\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=42)\n",
    "    km.fit(iris_df[feature_cols])\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_values, inertia, 'bo-')\n",
    "plt.xlabel('Number of Clusters k')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c: Visualize clusters (petal length vs width) for k=3\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='petal length (cm)', y='petal width (cm)', hue='cluster_k3',\n",
    "                palette='Set1', data=iris_df)\n",
    "plt.title('K-Means Clusters (k=3)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d: Cluster Analysis (Sample 150-200 words)\n",
    "# ----------------------------\n",
    "cluster_analysis = \"\"\"\n",
    "The K-Means clustering with k=3 successfully identified the three natural species clusters within the Iris dataset. \n",
    "The Adjusted Rand Index (ARI) indicates a strong alignment with actual species, suggesting high-quality clustering. \n",
    "Some misclassifications occur mainly between 'versicolor' and 'virginica', likely due to overlapping feature values in petal length and width. \n",
    "The elbow curve confirms k=3 as an optimal number of clusters, with diminishing inertia reduction for higher k. \n",
    "Visualizing clusters using petal length and width shows clear separation of 'setosa', while the other two species slightly overlap. \n",
    "In real-world applications, such clustering techniques are useful for customer segmentation, product categorization, and market analysis. \n",
    "If synthetic data were used, results might differ due to noise and variations in generated features, potentially affecting cluster purity and ARI scores.\n",
    "\"\"\"\n",
    "print(cluster_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5fdbf",
   "metadata": {},
   "source": [
    "# Task 3: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ebef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(dt_model, feature_names=X_train.columns, class_names=label_encoder.classes_, filled=True)\n",
    "plt.title(\"Decision Tree for Iris Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b59fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (k=5)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"KNN Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=label_encoder.classes_))\n",
    "\n",
    "# Compare accuracies\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7433b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Task 3: Association Rule Mining\n",
    "# =========================================\n",
    "\n",
    "import random\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Generate synthetic transactions\n",
    "items_pool = ['milk','bread','beer','diapers','eggs','cheese','butter','coffee','tea','sugar',\n",
    "              'apples','bananas','chocolate','cereal','yogurt','ham','juice','water','chips','cookies']\n",
    "\n",
    "transactions = [random.sample(items_pool, k=random.randint(3,8)) for _ in range(30)]\n",
    "\n",
    "# One-hot encode\n",
    "all_items = sorted(items_pool)\n",
    "encoded_vals = []\n",
    "for t in transactions:\n",
    "    row = {item: (item in t) for item in all_items}\n",
    "    encoded_vals.append(row)\n",
    "df_transactions = pd.DataFrame(encoded_vals)\n",
    "\n",
    "# Apriori\n",
    "frequent_itemsets = apriori(df_transactions, min_support=0.2, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
    "\n",
    "# Top 5 rules by lift\n",
    "rules_sorted = rules.sort_values(by='lift', ascending=False)\n",
    "print(\"Top 5 Association Rules:\\n\", rules_sorted.head())\n",
    "\n",
    "# Analyze one rule\n",
    "sample_rule = rules_sorted.iloc[0]\n",
    "print(\"\\nSample Rule Analysis:\")\n",
    "print(f\"Rule: {sample_rule['antecedents']} -> {sample_rule['consequents']}\")\n",
    "print(f\"Support: {sample_rule['support']:.2f}, Confidence: {sample_rule['confidence']:.2f}, Lift: {sample_rule['lift']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".end-sem (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
