{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1db178",
   "metadata": {},
   "source": [
    "### *Load and preprocess the dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e452857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffea8cd",
   "metadata": {},
   "source": [
    "*Description:*\n",
    "\n",
    "*This chunk focuses on loading the raw dataset from a CSV file into a pandas DataFrame, ensuring that special characters in the data are correctly handled by specifying the appropriate encoding. The 'InvoiceDate' column is explicitly converted into a datetime object, which enables more efficient and accurate manipulation of date and time data. To make the dataset appear current for analysis purposes, all invoice dates are shifted forward by 14 years, adjusting the original 2010-2011 timestamps to approximately 2024-2025. This simulated recency of the data can be important for testing or reporting. Finally, the new date range is printed as a sanity check to confirm that the shift was applied correctly.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e508ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range after shifting: 2024-12-01 08:26:00 to 2025-12-09 12:50:00\n"
     ]
    }
   ],
   "source": [
    "# Load dataset CSV into pandas DataFrame.\n",
    "# Encoding ISO-8859-1 is used to handle special characters.\n",
    "df = pd.read_csv('../Data/Online_Retail.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Convert 'InvoiceDate' column to datetime type for easier date/time operations.\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Shift invoice dates forward by 14 years to simulate current data (2024-2025).\n",
    "df['InvoiceDate'] = df['InvoiceDate'] + pd.DateOffset(years=14)\n",
    "\n",
    "# Verify date range after shifting.\n",
    "print(\"Date range after shifting:\", df['InvoiceDate'].min(), \"to\", df['InvoiceDate'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb481e",
   "metadata": {},
   "source": [
    "### *Create Time Dimension Table (TimeDim)*\n",
    "*Description:*\n",
    "\n",
    "*In this step, a Time Dimension table is constructed, which is fundamental in data warehousing and analytical processing for providing rich temporal context to sales data. The process starts by extracting all unique dates from the transactional data and normalizing them to remove time components, ensuring that each date appears only once. A unique `TimeID` is generated for each date using the YYYYMMDD format, facilitating efficient joins with fact tables. Additional columns are created to break down each date into components such as day, month, quarter, year, and week number — all valuable for time-based grouping and trend analysis. This denormalized structure simplifies querying and reporting over time.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "155e0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the Time Dimension (TimeDim) table\n",
    "# Create empty DataFrame for Time Dimension\n",
    "time_dim = pd.DataFrame()\n",
    "\n",
    "# Extract unique dates from the 'InvoiceDate' column (date only, no time)\n",
    "time_dim['FullDate'] = pd.to_datetime(df['InvoiceDate'].dt.date.unique())\n",
    "\n",
    "# Generate a unique TimeID for each date in YYYYMMDD integer format\n",
    "time_dim['TimeID'] = time_dim['FullDate'].dt.strftime('%Y%m%d').astype(int)\n",
    "\n",
    "# Extract useful date attributes for analysis\n",
    "time_dim['Day'] = time_dim['FullDate'].dt.day\n",
    "time_dim['Month'] = time_dim['FullDate'].dt.month\n",
    "time_dim['Quarter'] = time_dim['FullDate'].dt.quarter\n",
    "time_dim['Year'] = time_dim['FullDate'].dt.year\n",
    "time_dim['WeekOfYear'] = time_dim['FullDate'].dt.isocalendar().week\n",
    "\n",
    "# Reorder columns for clarity\n",
    "time_dim = time_dim[['TimeID', 'FullDate', 'Day', 'Month', 'Quarter', 'Year', 'WeekOfYear']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a56ff",
   "metadata": {},
   "source": [
    "### *Create Customer Dimension Table (CustomerDim)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e72f7b",
   "metadata": {},
   "source": [
    "*Description:*\n",
    "\n",
    "*This chunk builds the Customer Dimension table, which profiles unique customers using a combination of actual and synthetic data. The real `CustomerID` and country information are directly extracted to maintain referential integrity. Since personal identifying information like names and cities are not available or desirable to use, synthetic values are generated to enrich the dataset while preserving privacy. Customer names are created by hashing the `CustomerID` to produce consistent yet anonymous identifiers. Cities are generated using the Faker library with locale settings based on the customer’s country, adding realistic geographic diversity. Additionally, plausible gender and age values are randomly assigned within reasonable bounds to simulate demographic attributes. Finally, the earliest invoice date is used as a proxy for the customer’s registration date, providing a temporal reference for customer activity.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4c2808f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CustomerName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerSince",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "2541f2b0-a8b1-47ca-897b-6c4cf7fe2d6f",
       "rows": [
        [
         "0",
         "17850.0",
         "United Kingdom",
         "54cde5dbb6",
         "Amberport",
         "Female",
         "42",
         "2024-12-01 08:26:00"
        ],
        [
         "9",
         "13047.0",
         "United Kingdom",
         "86314fa849",
         "West Joshua",
         "Other",
         "26",
         "2024-12-01 08:26:00"
        ],
        [
         "26",
         "12583.0",
         "France",
         "dcff63cd99",
         "East Shannonbury",
         "Female",
         "52",
         "2024-12-01 08:26:00"
        ],
        [
         "46",
         "13748.0",
         "United Kingdom",
         "590354e49f",
         "Malcolmberg",
         "Female",
         "33",
         "2024-12-01 08:26:00"
        ],
        [
         "65",
         "15100.0",
         "United Kingdom",
         "58ec7997a6",
         "Port Raymond",
         "Other",
         "62",
         "2024-12-01 08:26:00"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>City</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>CustomerSince</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54cde5dbb6</td>\n",
       "      <td>Amberport</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2024-12-01 08:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13047.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>86314fa849</td>\n",
       "      <td>West Joshua</td>\n",
       "      <td>Other</td>\n",
       "      <td>26</td>\n",
       "      <td>2024-12-01 08:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "      <td>dcff63cd99</td>\n",
       "      <td>East Shannonbury</td>\n",
       "      <td>Female</td>\n",
       "      <td>52</td>\n",
       "      <td>2024-12-01 08:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13748.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>590354e49f</td>\n",
       "      <td>Malcolmberg</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-12-01 08:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>15100.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>58ec7997a6</td>\n",
       "      <td>Port Raymond</td>\n",
       "      <td>Other</td>\n",
       "      <td>62</td>\n",
       "      <td>2024-12-01 08:26:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID         Country CustomerName              City  Gender  Age  \\\n",
       "0      17850.0  United Kingdom   54cde5dbb6         Amberport  Female   42   \n",
       "9      13047.0  United Kingdom   86314fa849       West Joshua   Other   26   \n",
       "26     12583.0          France   dcff63cd99  East Shannonbury  Female   52   \n",
       "46     13748.0  United Kingdom   590354e49f       Malcolmberg  Female   33   \n",
       "65     15100.0  United Kingdom   58ec7997a6      Port Raymond   Other   62   \n",
       "\n",
       "         CustomerSince  \n",
       "0  2024-12-01 08:26:00  \n",
       "9  2024-12-01 08:26:00  \n",
       "26 2024-12-01 08:26:00  \n",
       "46 2024-12-01 08:26:00  \n",
       "65 2024-12-01 08:26:00  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "def hash_customer_name(cust_id):\n",
    "    # Generate a synthetic name by hashing the CustomerID\n",
    "    return hashlib.sha256(str(cust_id).encode()).hexdigest()[:10]\n",
    "\n",
    "def generate_city_based_on_country(country):\n",
    "    # Use Faker locale based on country for city name if possible, else default locale\n",
    "    # Here we simplify: if country is UK use en_GB, else en_US or default\n",
    "    if country == 'United Kingdom':\n",
    "        fake_local = Faker('en_GB')\n",
    "    else:\n",
    "        fake_local = Faker()\n",
    "    return fake_local.city()\n",
    "\n",
    "# Extract unique customers with country\n",
    "customer_dim = df[['CustomerID', 'Country']].drop_duplicates().copy()\n",
    "\n",
    "# Create synthetic CustomerName by hashing CustomerID\n",
    "customer_dim['CustomerName'] = customer_dim['CustomerID'].apply(hash_customer_name)\n",
    "\n",
    "# Generate synthetic City based on Country\n",
    "customer_dim['City'] = customer_dim['Country'].apply(generate_city_based_on_country)\n",
    "\n",
    "# Generate reasonable synthetic Gender and Age\n",
    "gender_choices = ['Male', 'Female', 'Other']\n",
    "customer_dim['Gender'] = [random.choice(gender_choices) for _ in range(len(customer_dim))]\n",
    "customer_dim['Age'] = [random.randint(18, 75) for _ in range(len(customer_dim))]\n",
    "\n",
    "# Set CustomerSince as earliest InvoiceDate in the dataset\n",
    "customer_dim['CustomerSince'] = df['InvoiceDate'].min()\n",
    "\n",
    "# Drop Email column (not required)\n",
    "# No Email column added here\n",
    "\n",
    "customer_dim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b1586",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "936c2de9",
   "metadata": {},
   "source": [
    "### *Create Store Dimension Table (StoreDim)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c637d7",
   "metadata": {},
   "source": [
    "\n",
    "*Description:*\n",
    "\n",
    "*This step constructs the Store Dimension table, which represents the stores or sales locations for transactions. Since the dataset primarily references countries rather than specific store locations, each unique country is treated as a distinct store. Unique numeric `StoreID`s are assigned for efficient foreign key references. Store names are generated to include the country name for clarity and uniqueness. The sales channel is hardcoded as \"Online,\" reflecting the dataset's nature as online retail transactions. To provide richer location information, synthetic cities are generated for each store based on the country, using locale-specific Faker instances to maintain geographic plausibility. This approach allows analysis at the store level while enhancing location details without requiring real-world addresses.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f2c0afb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "StoreID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "StoreName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Channel",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "City",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5a0c462e-d2c4-411b-8370-116d6d4ece6a",
       "rows": [
        [
         "0",
         "United Kingdom",
         "1",
         "Online Store - United Kingdom",
         "Online",
         "Marianmouth"
        ],
        [
         "1",
         "France",
         "2",
         "Online Store - France",
         "Online",
         "North Teresa"
        ],
        [
         "2",
         "Australia",
         "3",
         "Online Store - Australia",
         "Online",
         "Aguilarport"
        ],
        [
         "3",
         "Netherlands",
         "4",
         "Online Store - Netherlands",
         "Online",
         "East Stephanie"
        ],
        [
         "4",
         "Germany",
         "5",
         "Online Store - Germany",
         "Online",
         "Jamestown"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>StoreName</th>\n",
       "      <th>Channel</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>Online Store - United Kingdom</td>\n",
       "      <td>Online</td>\n",
       "      <td>Marianmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>France</td>\n",
       "      <td>2</td>\n",
       "      <td>Online Store - France</td>\n",
       "      <td>Online</td>\n",
       "      <td>North Teresa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>3</td>\n",
       "      <td>Online Store - Australia</td>\n",
       "      <td>Online</td>\n",
       "      <td>Aguilarport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>4</td>\n",
       "      <td>Online Store - Netherlands</td>\n",
       "      <td>Online</td>\n",
       "      <td>East Stephanie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>5</td>\n",
       "      <td>Online Store - Germany</td>\n",
       "      <td>Online</td>\n",
       "      <td>Jamestown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country  StoreID                      StoreName Channel  \\\n",
       "0  United Kingdom        1  Online Store - United Kingdom  Online   \n",
       "1          France        2          Online Store - France  Online   \n",
       "2       Australia        3       Online Store - Australia  Online   \n",
       "3     Netherlands        4     Online Store - Netherlands  Online   \n",
       "4         Germany        5         Online Store - Germany  Online   \n",
       "\n",
       "             City  \n",
       "0     Marianmouth  \n",
       "1    North Teresa  \n",
       "2     Aguilarport  \n",
       "3  East Stephanie  \n",
       "4       Jamestown  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique countries as stores\n",
    "store_dim = df[['Country']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Assign unique StoreID starting from 1\n",
    "store_dim['StoreID'] = store_dim.index + 1\n",
    "\n",
    "# Assign StoreName with country suffix for uniqueness\n",
    "store_dim['StoreName'] = store_dim['Country'].apply(lambda x: f\"Online Store - {x}\")\n",
    "\n",
    "# Assign Channel as 'Online' (dataset is online retail)\n",
    "store_dim['Channel'] = 'Online'\n",
    "\n",
    "# Generate synthetic City based on country using Faker locales\n",
    "def generate_city(country):\n",
    "    if country == 'United Kingdom':\n",
    "        fake_local = Faker('en_GB')\n",
    "    else:\n",
    "        fake_local = Faker()\n",
    "    return fake_local.city()\n",
    "\n",
    "store_dim['City'] = store_dim['Country'].apply(generate_city)\n",
    "\n",
    "store_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6aade59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ProductID                          ProductName  UnitCost       Category  \\\n",
      "0    85123A   WHITE HANGING HEART T-LIGHT HOLDER      2.55  Miscellaneous   \n",
      "1     71053                  WHITE METAL LANTERN      3.39  Miscellaneous   \n",
      "2    84406B       CREAM CUPID HEARTS COAT HANGER      2.75  Miscellaneous   \n",
      "3    84029G  KNITTED UNION FLAG HOT WATER BOTTLE      3.39  Miscellaneous   \n",
      "4    84029E       RED WOOLLY HOTTIE WHITE HEART.      3.39  Miscellaneous   \n",
      "\n",
      "                            Brand  \n",
      "0  Carter, Richardson and Frazier  \n",
      "1         Smith, Scott and Obrien  \n",
      "2                    Ware-Sellers  \n",
      "3            Liu, Moss and Garcia  \n",
      "4    Bailey, Salazar and Phillips  \n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "# 4. Create Product Dimension Table (product_dim)\n",
    "# ------------------------------------------------\n",
    "# Extract unique products from the original dataset: StockCode, Description, UnitPrice.\n",
    "product_dim = df[['StockCode', 'Description', 'UnitPrice']].drop_duplicates().copy()\n",
    "\n",
    "# Rename columns to fit dimensional model schema\n",
    "product_dim = product_dim.rename(columns={\n",
    "    'StockCode': 'ProductID',\n",
    "    'Description': 'ProductName',\n",
    "    'UnitPrice': 'UnitCost'\n",
    "})\n",
    "\n",
    "# Define a simple function to categorize products based on keywords in ProductName\n",
    "def categorize_product(name):\n",
    "    if pd.isna(name):\n",
    "        return 'Miscellaneous'\n",
    "    name = name.lower()\n",
    "    if any(keyword in name for keyword in ['electronic', 'computer', 'usb', 'laptop', 'cable']):\n",
    "        return 'Electronics'\n",
    "    elif any(keyword in name for keyword in ['shirt', 'clothing', 'dress', 't-shirt', 'jeans']):\n",
    "        return 'Clothing'\n",
    "    elif any(keyword in name for keyword in ['book', 'novel', 'journal']):\n",
    "        return 'Books'\n",
    "    elif any(keyword in name for keyword in ['toy', 'game']):\n",
    "        return 'Toys & Games'\n",
    "    else:\n",
    "        return 'Miscellaneous'\n",
    "\n",
    "# Apply the category function to create a Category column\n",
    "product_dim['Category'] = product_dim['ProductName'].apply(categorize_product)\n",
    "\n",
    "# Generate a synthetic Brand name using Faker company names for each product\n",
    "product_dim['Brand'] = [fake.company() for _ in range(len(product_dim))]\n",
    "\n",
    "# Display sample of product_dim to verify\n",
    "print(product_dim.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f4b13c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'InvoiceDate' to datetime if not already\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Create a new column 'InvoiceDateOnly' normalized to midnight (date only, no time)\n",
    "df['InvoiceDateOnly'] = df['InvoiceDate'].dt.normalize()\n",
    "\n",
    "# Ensure 'FullDate' in time_dim is datetime type for correct merging\n",
    "time_dim['FullDate'] = pd.to_datetime(time_dim['FullDate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52c621d",
   "metadata": {},
   "source": [
    "### *Prepare FactSales Table (Fact Table)*\n",
    "\n",
    "*Description:*\n",
    "\n",
    "*This final chunk assembles the FactSales table, which records individual sales transactions linked to the various dimension tables through foreign keys. First, any encoding issues in column names are corrected to ensure consistency. Duplicate columns created through multiple merges are removed to avoid confusion and errors. The fact table is enriched by merging the Time Dimension to include a `TimeID` foreign key, facilitating time-based joins and analysis. Invoice dates are normalized to exclude time information, aligning with the date-only nature of the Time Dimension. The product identifier is standardized by assigning `ProductID` as the original stock code. The store foreign key (`StoreID`) is merged in based on country, linking sales to store locations. A key metric, `TotalSales`, is calculated by multiplying the quantity sold by the unit price, providing the total revenue per transaction line. Finally, only the relevant columns necessary for the fact table schema are selected to form the `fact_sales` DataFrame, ready for analytical queries or database loading.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0028bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'ï»¿InvoiceNo': 'InvoiceNo'})\n",
    "# Use the 'TimeID' and 'StoreID' columns without suffixes if present\n",
    "if 'TimeID' not in df.columns:\n",
    "    if 'TimeID_y' in df.columns:\n",
    "        df['TimeID'] = df['TimeID_y']\n",
    "    elif 'TimeID_x' in df.columns:\n",
    "        df['TimeID'] = df['TimeID_x']\n",
    "\n",
    "if 'StoreID' not in df.columns:\n",
    "    if 'StoreID_y' in df.columns:\n",
    "        df['StoreID'] = df['StoreID_y']\n",
    "    elif 'StoreID_x' in df.columns:\n",
    "        df['StoreID'] = df['StoreID_x']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3b283e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "e94932c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df with time_dim to get TimeID by matching on normalized date columns\n",
    "df = df.merge(\n",
    "    time_dim[['TimeID', 'FullDate']],\n",
    "    left_on='InvoiceDateOnly',\n",
    "    right_on='FullDate',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convert 'InvoiceDate' column to just date (drop time component) for fact table compatibility\n",
    "df['InvoiceDate'] = df['InvoiceDate'].dt.date\n",
    "\n",
    "# Assign 'ProductID' as the same value as 'StockCode' for clarity and schema matching\n",
    "df['ProductID'] = df['StockCode']\n",
    "\n",
    "# Merge df with store_dim on 'Country' to get StoreID foreign key\n",
    "df = df.merge(\n",
    "    store_dim[['StoreID', 'Country']],\n",
    "    on='Country',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate total sales amount per transaction line\n",
    "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "#  Add Discount column if missing (assumed 0)\n",
    "if 'Discount' not in df.columns:\n",
    "    df['Discount'] = 0\n",
    "\n",
    "# Then select the columns including Discount\n",
    "fact_sales = df[['InvoiceNo', 'InvoiceDate', 'TimeID', 'ProductID', 'CustomerID', 'StoreID',\n",
    "                 'Quantity', 'UnitPrice', 'Discount', 'TotalSales']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cc812299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dimension and fact tables have been saved to the folder 'Task_2_ETL_Process_Implementation/synthetic_data'.\n",
      "Files in the folder now:\n",
      "['CustomerDim.csv', 'FactSales.csv', 'ProductDim.csv', 'StoreDim.csv', 'TimeDim.csv']\n"
     ]
    }
   ],
   "source": [
    "# Define the folder path\n",
    "folder_path = 'Task_2_ETL_Process_Implementation/synthetic_data'\n",
    "\n",
    "# Create folder if it does not exist (won't error if it exists)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Save each DataFrame to a separate CSV file inside the folder\n",
    "time_dim.to_csv(os.path.join(folder_path, 'TimeDim.csv'), index=False)\n",
    "customer_dim.to_csv(os.path.join(folder_path, 'CustomerDim.csv'), index=False)\n",
    "store_dim.to_csv(os.path.join(folder_path, 'StoreDim.csv'), index=False)\n",
    "# Assuming product_dim exists\n",
    "product_dim.to_csv(os.path.join(folder_path, 'ProductDim.csv'), index=False)\n",
    "fact_sales.to_csv(os.path.join(folder_path, 'FactSales.csv'), index=False)\n",
    "\n",
    "print(f\"All dimension and fact tables have been saved to the folder '{folder_path}'.\")\n",
    "\n",
    "# List all files in the folder to confirm\n",
    "print(\"Files in the folder now:\")\n",
    "print(os.listdir(folder_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".end-sem (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
