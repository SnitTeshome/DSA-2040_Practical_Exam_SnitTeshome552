{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c793b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def memory_safe_merge(folder_path, merge_key='CustomerID', output_file='merged.parquet'):\n",
    "    \"\"\"\n",
    "    Merges Parquet files with minimal memory usage:\n",
    "    1. Processes files sequentially\n",
    "    2. Uses chunked reading/writing\n",
    "    3. Maintains consistent schema\n",
    "    \"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    parquet_files = list(folder_path.glob('*.parquet'))\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise FileNotFoundError(f\"No Parquet files found in {folder_path}\")\n",
    "\n",
    "    # Process first file\n",
    "    first_file = parquet_files[0]\n",
    "    print(f\"Processing {first_file.name} as base...\")\n",
    "    base_df = pd.read_parquet(first_file)\n",
    "    \n",
    "    # Initialize merged file\n",
    "    base_df.to_parquet(output_file)\n",
    "    del base_df\n",
    "    \n",
    "    # Process remaining files\n",
    "    for file in parquet_files[1:]:\n",
    "        print(f\"\\nMerging {file.name}...\")\n",
    "        \n",
    "        # Read file to get schema\n",
    "        file_df = pd.read_parquet(file)\n",
    "        \n",
    "        # Check if merge key exists\n",
    "        if merge_key not in file_df.columns:\n",
    "            print(f\"Warning: {merge_key} not found - concatenating instead\")\n",
    "            existing_data = pd.read_parquet(output_file)\n",
    "            pd.concat([existing_data, file_df]).to_parquet(output_file)\n",
    "            continue\n",
    "            \n",
    "        # Get common columns (fixed syntax)\n",
    "        existing_cols = pd.read_parquet(output_file, columns=[merge_key]).columns.tolist()\n",
    "        common_cols = list(set(existing_cols + [merge_key]))\n",
    "        \n",
    "        # Process in chunks\n",
    "        chunk_size = 50000\n",
    "        for i, chunk in enumerate(pd.read_parquet(file, chunksize=chunk_size)):\n",
    "            print(f\"Processing chunk {i+1}...\", end='\\r')\n",
    "            \n",
    "            # Read corresponding base chunks\n",
    "            base_chunk = pd.read_parquet(\n",
    "                output_file,\n",
    "                filters=[(merge_key, 'in', chunk[merge_key].unique().tolist())]\n",
    "            )\n",
    "            \n",
    "            # Merge chunks\n",
    "            merged_chunk = pd.merge(\n",
    "                base_chunk,\n",
    "                chunk,\n",
    "                on=merge_key,\n",
    "                how='outer',\n",
    "                suffixes=('', '_DROP')\n",
    "            )\n",
    "            \n",
    "            # Clean and save\n",
    "            merged_chunk = merged_chunk.loc[:, ~merged_chunk.columns.str.endswith('_DROP')]\n",
    "            \n",
    "            # Update output file\n",
    "            if i == 0:\n",
    "                merged_chunk.to_parquet(output_file)\n",
    "            else:\n",
    "                existing = pd.read_parquet(output_file)\n",
    "                pd.concat([existing, merged_chunk]).to_parquet(output_file)\n",
    "    \n",
    "    print(\"\\nMerge complete!\")\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def execute_olap_queries(merged_file):\n",
    "    \"\"\"\n",
    "    Executes OLAP queries on the merged data in memory-efficient chunks\n",
    "    Returns dictionary with query results and saves visualizations\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. ROLL-UP: Sales by Country and Quarter (in chunks)\n",
    "    print(\"Executing ROLL-UP: Sales by Country/Quarter...\")\n",
    "    rollup_results = pd.DataFrame()\n",
    "    for chunk in pd.read_parquet(merged_file, chunksize=100000):\n",
    "        chunk['Quarter'] = pd.to_datetime(chunk['InvoiceDate']).dt.quarter\n",
    "        chunk_result = chunk.groupby(['Country', 'Quarter'])['TotalSales'].sum().reset_index()\n",
    "        rollup_results = pd.concat([rollup_results, chunk_result])\n",
    "    \n",
    "    # Aggregate chunked results\n",
    "    rollup_final = rollup_results.groupby(['Country', 'Quarter'])['TotalSales'].sum().reset_index()\n",
    "    results['rollup'] = rollup_final\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_countries = rollup_final.groupby('Country')['TotalSales'].sum().nlargest(5).index\n",
    "    for country in top_countries:\n",
    "        country_data = rollup_final[rollup_final['Country'] == country]\n",
    "        plt.plot(country_data['Quarter'], country_data['TotalSales'], label=country, marker='o')\n",
    "    plt.title('Quarterly Sales by Top Countries')\n",
    "    plt.xlabel('Quarter')\n",
    "    plt.ylabel('Total Sales')\n",
    "    plt.legend()\n",
    "    plt.savefig('quarterly_sales.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. DRILL-DOWN: Monthly sales for top country\n",
    "    top_country = rollup_final.groupby('Country')['TotalSales'].sum().idxmax()\n",
    "    print(f\"\\nExecuting DRILL-DOWN for {top_country}...\")\n",
    "    \n",
    "    monthly_sales = pd.DataFrame()\n",
    "    for chunk in pd.read_parquet(merged_file, chunksize=100000):\n",
    "        chunk_dates = pd.to_datetime(chunk['InvoiceDate'])\n",
    "        chunk = chunk[chunk['Country'] == top_country].copy()\n",
    "        chunk['Month'] = chunk_dates.dt.month\n",
    "        chunk['MonthName'] = chunk_dates.dt.month_name()\n",
    "        monthly_sales = pd.concat([monthly_sales, chunk])\n",
    "    \n",
    "    drilldown_final = monthly_sales.groupby(['Month', 'MonthName'])['TotalSales'].sum().reset_index()\n",
    "    results['drilldown'] = drilldown_final\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(drilldown_final['MonthName'], drilldown_final['TotalSales'])\n",
    "    plt.title(f'Monthly Sales for {top_country}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(f'monthly_sales_{top_country}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. SLICE: Electronics sales by country\n",
    "    print(\"\\nExecuting SLICE: Electronics sales by country...\")\n",
    "    electronics_sales = pd.DataFrame()\n",
    "    for chunk in pd.read_parquet(merged_file, chunksize=100000):\n",
    "        if 'Category' in chunk.columns:\n",
    "            chunk_slice = chunk[chunk['Category'] == 'Electronics']\n",
    "            electronics_sales = pd.concat([electronics_sales, chunk_slice])\n",
    "    \n",
    "    if len(electronics_sales) > 0:\n",
    "        slice_final = electronics_sales.groupby('Country')['TotalSales'].sum().nlargest(10).reset_index()\n",
    "        results['slice'] = slice_final\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.bar(slice_final['Country'], slice_final['TotalSales'])\n",
    "        plt.title('Top Countries for Electronics Sales')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.savefig('electronics_sales.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"No electronics data found\")\n",
    "        results['slice'] = None\n",
    "    \n",
    "    # Save results to CSV\n",
    "    rollup_final.to_csv('rollup_results.csv', index=False)\n",
    "    drilldown_final.to_csv('drilldown_results.csv', index=False)\n",
    "    if 'slice' in results and results['slice'] is not None:\n",
    "        results['slice'].to_csv('electronics_sales.csv', index=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Execute the analysis\n",
    "merged_file = 'merged.parquet'  # From previous step\n",
    "try:\n",
    "    olap_results = execute_olap_queries(merged_file)\n",
    "    \n",
    "    print(\"\\nOLAP Analysis Complete!\")\n",
    "    print(\"Generated Files:\")\n",
    "    print(\"- quarterly_sales.png\")\n",
    "    print(f\"- monthly_sales_[country].png\")\n",
    "    print(\"- electronics_sales.png (if data exists)\")\n",
    "    print(\"- CSV files with raw results\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nTop Countries by Quarterly Sales:\")\n",
    "    print(olap_results['rollup'].groupby('Country')['TotalSales'].sum().nlargest(5))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nAnalysis failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5843d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def analyze_merged_data(merged_df):\n",
    "    \"\"\"Perform OLAP analysis on the merged dataframe\"\"\"\n",
    "    # Data Quality Checks\n",
    "    print(\"\\n=== Data Quality Check ===\")\n",
    "    print(f\"Total rows: {len(merged_df)}\")\n",
    "    print(\"Null values per column:\")\n",
    "    print(merged_df.isnull().sum().sort_values(ascending=False))\n",
    "    \n",
    "    # Convert and validate InvoiceDate\n",
    "    merged_df['InvoiceDate'] = pd.to_datetime(merged_df['InvoiceDate'], errors='coerce')\n",
    "    date_nulls = merged_df['InvoiceDate'].isnull().sum()\n",
    "    if date_nulls > 0:\n",
    "        print(f\"\\nWarning: {date_nulls} rows have invalid dates\")\n",
    "    \n",
    "    # Create time dimensions\n",
    "    merged_df['Year'] = merged_df['InvoiceDate'].dt.year\n",
    "    merged_df['Quarter'] = merged_df['InvoiceDate'].dt.quarter\n",
    "    merged_df['Month'] = merged_df['InvoiceDate'].dt.month\n",
    "    merged_df['MonthName'] = merged_df['InvoiceDate'].dt.month_name()\n",
    "    \n",
    "    # Ensure numeric fields\n",
    "    for col in ['Quantity', 'UnitPrice', 'TotalSales']:\n",
    "        if col in merged_df.columns:\n",
    "            merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "    \n",
    "    # OLAP Query 1: ROLL-UP by Country and Quarter\n",
    "    try:\n",
    "        rollup = merged_df.groupby(['Country', 'Year', 'Quarter'])['TotalSales'].sum().reset_index()\n",
    "        print(\"\\nROLL-UP Results (Top 10 Countries):\")\n",
    "        print(rollup.groupby('Country')['TotalSales'].sum().nlargest(10))\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        for country in rollup['Country'].value_counts().index[:5]:\n",
    "            country_data = rollup[rollup['Country'] == country]\n",
    "            plt.plot(\n",
    "                country_data['Year'].astype(str) + \"Q\" + country_data['Quarter'].astype(str),\n",
    "                country_data['TotalSales'],\n",
    "                label=country,\n",
    "                marker='o'\n",
    "            )\n",
    "        plt.title('Quarterly Sales by Country')\n",
    "        plt.ylabel('Total Sales')\n",
    "        plt.xlabel('Quarter')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('quarterly_sales.png', dpi=300)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nRoll-up failed: {str(e)}\")\n",
    "\n",
    "    # OLAP Query 2: DRILL-DOWN for top country\n",
    "    try:\n",
    "        top_country = merged_df.groupby('Country')['TotalSales'].sum().idxmax()\n",
    "        drilldown = merged_df[merged_df['Country'] == top_country].groupby(\n",
    "            ['Year', 'Month', 'MonthName'])['TotalSales'].sum().reset_index()\n",
    "        \n",
    "        print(f\"\\nDRILL-DOWN for {top_country}:\")\n",
    "        print(drilldown)\n",
    "        \n",
    "        # Visualization\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(drilldown['MonthName'], drilldown['TotalSales'])\n",
    "        plt.title(f'Monthly Sales for {top_country}')\n",
    "        plt.ylabel('Total Sales')\n",
    "        plt.xlabel('Month')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'monthly_sales_{top_country}.png', dpi=300)\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"\\nDrill-down failed: {str(e)}\")\n",
    "\n",
    "    # OLAP Query 3: SLICE by Category\n",
    "    if 'Category' in merged_df.columns:\n",
    "        try:\n",
    "            electronics_sales = merged_df[merged_df['Category'] == 'Electronics'].groupby(\n",
    "                'Country')['TotalSales'].sum().nlargest(10)\n",
    "            print(\"\\nSLICE for Electronics:\")\n",
    "            print(electronics_sales)\n",
    "            \n",
    "            # Visualization\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            electronics_sales.plot(kind='bar')\n",
    "            plt.title('Top Countries for Electronics Sales')\n",
    "            plt.ylabel('Total Sales')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('electronics_sales.png', dpi=300)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"\\nSlice failed: {str(e)}\")\n",
    "    else:\n",
    "        print(\"\\n'Category' column not available for slicing\")\n",
    "\n",
    "    # Save results\n",
    "    try:\n",
    "        with pd.ExcelWriter('olap_results.xlsx') as writer:\n",
    "            rollup.to_excel(writer, sheet_name='Rollup', index=False)\n",
    "            drilldown.to_excel(writer, sheet_name='Drilldown', index=False)\n",
    "            if 'Category' in merged_df.columns:\n",
    "                merged_df[merged_df['Category'] == 'Electronics'].to_excel(\n",
    "                    writer, sheet_name='Electronics', index=False)\n",
    "        print(\"\\nResults saved to olap_results.xlsx\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCould not save to Excel: {str(e)}\")\n",
    "        print(\"Saving to CSV instead...\")\n",
    "        rollup.to_csv('rollup_results.csv', index=False)\n",
    "        drilldown.to_csv('drilldown_results.csv', index=False)\n",
    "        if 'Category' in merged_df.columns:\n",
    "            merged_df[merged_df['Category'] == 'Electronics'].to_csv(\n",
    "                'electronics_sales.csv', index=False)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\"C:\\Users\\Snit Kahsay\\Desktop\\DSA-2040_Practical_Exam_SnitTeshome552\\Task_2_ETL_Process_Implementation\\Task_2_ETL_Process_Implementation\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting data merge...\")\n",
    "        merged_df = safe_merge_parquet(folder_path, merge_key='CustomerID')\n",
    "        \n",
    "        print(\"\\nStarting OLAP analysis...\")\n",
    "        analyze_merged_data(merged_df)\n",
    "        \n",
    "        print(\"\\nAnalysis complete! Check generated files:\")\n",
    "        print(\"- quarterly_sales.png\")\n",
    "        print(\"- monthly_sales_[country].png\")\n",
    "        print(\"- electronics_sales.png (if category exists)\")\n",
    "        print(\"- olap_results.xlsx (or CSV files)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nFatal error: {str(e)}\")\n",
    "        print(\"Check that:\")\n",
    "        print(\"1. Files exist in the specified folder\")\n",
    "        print(\"2. 'CustomerID' column exists in all files\")\n",
    "        print(\"3. You have sufficient memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5ab8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check basic DataFrame info\n",
    "print(\"\\n=== DataFrame Info ===\")\n",
    "print(f\"Total rows: {len(full_df)}\")\n",
    "print(f\"Columns: {full_df.columns.tolist()}\")\n",
    "print(f\"Null counts:\\n{full_df[['Country', 'InvoiceDate', 'Quantity']].isnull().sum()}\")\n",
    "\n",
    "# 2. Verify datetime conversion\n",
    "print(\"\\n=== Date Conversion Check ===\")\n",
    "print(f\"Date range: {full_df['InvoiceDate'].min()} to {full_df['InvoiceDate'].max()}\")\n",
    "print(f\"Quarter sample:\\n{full_df[['InvoiceDate', 'Quarter']].head()}\")\n",
    "\n",
    "# 3. Check category assignment\n",
    "print(\"\\n=== Category Check ===\")\n",
    "print(\"Category distribution:\")\n",
    "print(full_df['Category'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert InvoiceDate to datetime if it's not already\n",
    "full_df['InvoiceDate'] = pd.to_datetime(full_df['InvoiceDate'])\n",
    "\n",
    "# Create time dimensions\n",
    "full_df['Quarter'] = full_df['InvoiceDate'].dt.quarter\n",
    "full_df['Month'] = full_df['InvoiceDate'].dt.month\n",
    "full_df['MonthName'] = full_df['InvoiceDate'].dt.month_name()\n",
    "\n",
    "# Add product category (if not exists)\n",
    "# For this example, let's create a synthetic category based on StockCode\n",
    "if 'Category' not in full_df.columns:\n",
    "    # Simple categorization - in real scenario use proper mapping\n",
    "    full_df['Category'] = full_df['StockCode'].apply(\n",
    "        lambda x: 'Electronics' if str(x).startswith('5') \n",
    "        else ('Clothing' if str(x).startswith('2') \n",
    "              else 'Other')\n",
    "    )\n",
    "\n",
    "# OLAP Query 1: ROLL-UP - Total sales by Country and quarter\n",
    "rollup_result = full_df.groupby(['Country', 'Quarter'])['Quantity'].sum().reset_index()\n",
    "print(\"ROLL-UP Result (Sales by Country & Quarter):\")\n",
    "print(rollup_result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLAP Query 2: DRILL-DOWN - Sales for specific country by month\n",
    "specific_country = 'United Kingdom'  # Change as needed\n",
    "drilldown_result = full_df[full_df['Country'] == specific_country].groupby(\n",
    "    ['MonthName', 'Month'])['Quantity'].sum().reset_index().sort_values('Month')\n",
    "print(f\"\\nDRILL-DOWN Result (Sales for {specific_country} by Month):\")\n",
    "print(drilldown_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLAP Query 3: SLICE - Total sales for electronics category\n",
    "slice_result = full_df[full_df['Category'] == 'Electronics'].groupby(\n",
    "    'Country')['Quantity'].sum().reset_index().sort_values('Quantity', ascending=False)\n",
    "print(\"\\nSLICE Result (Electronics Sales by Country):\")\n",
    "print(slice_result.head(10))\n",
    "\n",
    "# Visualization for one query (Roll-up example)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for country in rollup_result['Country'].unique()[:5]:  # Top 5 countries\n",
    "    country_data = rollup_result[rollup_result['Country'] == country]\n",
    "    plt.plot(country_data['Quarter'], country_data['Quantity'], \n",
    "             label=country, marker='o')\n",
    "\n",
    "plt.title('Quarterly Sales Trends by Country')\n",
    "plt.xlabel('Quarter')\n",
    "plt.ylabel('Total Quantity Sold')\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('quarterly_sales_trends.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".end-sem (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
